{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a869682",
   "metadata": {},
   "source": [
    "# Final Project: Understanding Hired Rides in NYC - Group 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project\n",
    "\n",
    "import math\n",
    "from math import tan\n",
    "import geopandas\n",
    "from geopandas import GeoSeries,GeoDataFrame\n",
    "\n",
    "import re\n",
    "import bs4\n",
    "import requests\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keplergl import KeplerGl\n",
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any general notebook setup, like log formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Distance\n",
    "- 1. Define a function that calculates the distance between two coordinates in kilometers that only uses the math module from the standard library\n",
    "- 2. Use calculate_distance function to add distance column to each Uber and Yellow Taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import pi\n",
    "EARTH_RADIUS = 6378.137\n",
    "def rad(d):\n",
    "    return d * pi / 180.0\n",
    "\n",
    "def calculate_distance(from_coord, to_coord):\n",
    "    lat1 = from_coord[0]\n",
    "    lng1 = from_coord[1]\n",
    "    lat2 = to_coord[0]\n",
    "    lng2 = to_coord[1]\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * math.asin(\n",
    "        math.sqrt(math.pow(math.sin(a / 2), 2) + math.cos(radLat1) * math.cos(radLat2) * math.pow(math.sin(b / 2), 2)))\n",
    "    s = s * EARTH_RADIUS\n",
    "    return s   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    distance_list = []\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        from_coord  = (dataframe[\"pickup_latitude\"][i], dataframe[\"pickup_longitude\"][i])\n",
    "        to_coord  = (dataframe[\"dropoff_latitude\"][i], dataframe[\"dropoff_longitude\"][i])\n",
    "        distance_list.append(calculate_distance(from_coord, to_coord))\n",
    "    dataframe[\"cal_distance\"] = distance_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e6546",
   "metadata": {},
   "source": [
    "### Convert ID into Coordinates\n",
    "- 1. Get coordinates using the “center” of the zones (polygons) \n",
    "- 2. Convert ID into coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e8010d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from geopandas import GeoSeries,GeoDataFrame\n",
    "\n",
    "def get_lat_lon_from_loc():\n",
    "    gdf = geopandas.read_file(\"taxi_zones.shp\")\n",
    "    gdf = gdf.to_crs(4326)\n",
    "    lon = gdf.centroid.x\n",
    "    lat = gdf.centroid.y\n",
    "    gdf[\"lon\"] = lon\n",
    "    gdf[\"lat\"] = lat\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1202c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_id_into_lat_lon(all_sample_tables):\n",
    "    gdf = get_lat_lon_from_loc()\n",
    "    start_lon = []\n",
    "    start_lat = []\n",
    "    end_lon = []\n",
    "    end_lat = []\n",
    "    id_list = list(gdf[\"LocationID\"])\n",
    "    for i in range(all_sample_tables.shape[0]):\n",
    "        if 'PULocationID' in all_sample_tables.columns:\n",
    "            start_point = all_sample_tables[\"PULocationID\"][i]\n",
    "            end_point = all_sample_tables[\"DOLocationID\"][i]\n",
    "            if start_point in id_list:\n",
    "                index_location = gdf[ gdf[\"LocationID\"]==start_point ].index.values[0]\n",
    "                start_lon.append( float( gdf[\"lon\"][index_location] ) )\n",
    "                start_lat.append( float( gdf[\"lat\"][index_location] ) )\n",
    "            else:\n",
    "                start_lon.append(None)\n",
    "                start_lat.append(None)\n",
    "            if end_point in id_list:\n",
    "                index_location = gdf[ gdf[\"LocationID\"]==end_point ].index.values[0]\n",
    "                end_lon.append( float( gdf[\"lon\"][index_location] ) )\n",
    "                end_lat.append( float( gdf[\"lat\"][index_location] ) ) \n",
    "            else:\n",
    "                end_lon.append(None)\n",
    "                end_lat.append(None)\n",
    "        else:\n",
    "            start_lon.append(None)\n",
    "            start_lat.append(None)\n",
    "            end_lon.append(None)\n",
    "            end_lat.append(None)\n",
    "            \n",
    "    all_sample_tables[\"pickup_longitude\"] = start_lon\n",
    "    all_sample_tables[\"pickup_latitude\"] = start_lat\n",
    "    all_sample_tables[\"dropoff_longitude\"] = end_lon\n",
    "    all_sample_tables[\"dropoff_latitude\"] = end_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "- 1. Find the desired links of yellow taxi data\n",
    "- 2. Get and clean month taxi data (sample)\n",
    "- 3. Remove useless columns\n",
    "- 4. Process NAN value\n",
    "- 5. Convert ID into coordinate\n",
    "- 6. Convert date taxi data into YEAR, MONTH, DAY, HOUR and WEEK\n",
    "- 7. Get distance column of taxi data\n",
    "- 8. Generate taxi data (one gigantic dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5474c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datetime(all_sample_tables): # for part3 and part4 convenience; normalizing column names\n",
    "    if \"tpep_pickup_datetime\" in all_sample_tables.columns:\n",
    "        all_sample_tables['tpep_pickup_datetime'] = pd.to_datetime(all_sample_tables['tpep_pickup_datetime'])\n",
    "        all_sample_tables['YEAR'] = all_sample_tables['tpep_pickup_datetime'].dt.year.astype(int)\n",
    "        all_sample_tables['MONTH'] = all_sample_tables['tpep_pickup_datetime'].dt.month.astype(int)\n",
    "        all_sample_tables['DAY'] = all_sample_tables['tpep_pickup_datetime'].dt.day.astype(int)\n",
    "        all_sample_tables['HOUR'] = all_sample_tables['tpep_pickup_datetime'].dt.hour.astype(int)\n",
    "        all_sample_tables[\"WEEK\"] = all_sample_tables['tpep_pickup_datetime'].dt.dayofweek+1 # 0-6 to 1-7\n",
    "    else:\n",
    "        all_sample_tables['tpep_pickup_datetime'] = None\n",
    "        all_sample_tables['YEAR'] = None\n",
    "        all_sample_tables['MONTH'] = None\n",
    "        all_sample_tables['DAY'] = None\n",
    "        all_sample_tables['HOUR'] = None\n",
    "        all_sample_tables[\"WEEK\"] = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "def find_taxi_parquet_urls():\n",
    "    parquet_urls = []\n",
    "    res = requests.get(url=TAXI_URL)\n",
    "    soup = bs(res.text)\n",
    "    for i, link in enumerate(soup.findAll('a')): \n",
    "        new_url = link.get('href')\n",
    "        data_pattern = r'yellow_tripdata_201[012345]|2009'\n",
    "        if re.search(data_pattern, new_url):\n",
    "            if not re.search(r'2015\\-0[789]|2015\\-1[012]', new_url):\n",
    "                parquet_urls.append(new_url)     \n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddbc42b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_taxi_parquet_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import pandas as pd\n",
    "\n",
    "def get_and_clean_month_taxi_data(url):\n",
    "    import os\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', url)\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    \n",
    "    # if exists, no need to download\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name, 'wb') as f: \n",
    "            f.write(response.data)\n",
    "    response.release_conn()\n",
    "    pd_data = pd.read_parquet(file_name)\n",
    "    # for testing, we sample panda data\n",
    "    print(\"pd_data.shape : \", pd_data.shape)\n",
    "    \n",
    "    # sample 2564 for each month since 200,000/78 = 2564\n",
    "    # make it roughly equal to the sample size of the uber dataset\n",
    "    pd_data = pd_data.sample(2564)\n",
    "    pd_data = pd_data.reset_index()\n",
    "    print(pd_data.head()) \n",
    "    \n",
    "    # remove useless columns\n",
    "#    if \"2010\" not in file_name:\n",
    "#        pd_data = pd_data.drop([\"index\", \"VendorID\", \"passenger_count\", \"RatecodeID\", \"store_and_fwd_flag\",\\\n",
    "#                                    \"payment_type\", \"fare_amount\", \"mta_tax\", \"extra\", \"tolls_amount\", \\\n",
    "#                                    \"improvement_surcharge\", \"total_amount\", \"congestion_surcharge\", \"airport_fee\"], axis=1) \n",
    "#    else:\n",
    "#        pd_data = pd_data.drop([\"index\", \"passenger_count\", \"store_and_fwd_flag\",\\\n",
    "#                                    \"payment_type\", \"fare_amount\", \"mta_tax\", \"tolls_amount\", \\\n",
    "#                                     \"total_amount\"], axis=1)\n",
    "\n",
    "    print(\"sample data, pd_data.shape: \", pd_data.shape)\n",
    "\n",
    "    # process NAN value\n",
    "    print(pd_data.isnull().sum())\n",
    "    pd_data.fillna(axis=0, method=\"ffill\")\n",
    "    \n",
    "    if \"congestion_surcharge\" in pd_data.columns:\n",
    "        pd_data = pd_data.drop([\"congestion_surcharge\"], axis=1)\n",
    "    if \"airport_fee\" in pd_data.columns:\n",
    "        pd_data = pd_data.drop([\"airport_fee\"], axis=1)             \n",
    "    \n",
    "    convert_id_into_lat_lon(pd_data)\n",
    "    process_datetime(pd_data)\n",
    "\n",
    "    pd_data = pd_data.reset_index()    \n",
    "    return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    all_parquet_urls = find_taxi_parquet_urls()\n",
    "    i = 0\n",
    "    for parquet_url in all_parquet_urls:\n",
    "        if i > 3:\n",
    "            break\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(parquet_url)\n",
    "        add_distance_column(dataframe)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        i += 1\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    print(taxi_data.isnull().sum())\n",
    "    print(taxi_data.shape)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "- 1. Load and clean uber data\n",
    "- 2. Convert date uber data into YEAR, MONTH, DAY, HOUR and WEEK\n",
    "- 3. Get distance column of uber data\n",
    "- 4. Remove useless columns\n",
    "- 5. Process NAN value\n",
    "- 6. Genereate uber data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    pd_data = pd.read_csv(csv_file, index_col=0)\n",
    "    pd_data['pickup_datetime'] = pd.to_datetime(pd_data['pickup_datetime'])\n",
    "    pd_data['YEAR'] = pd_data['pickup_datetime'].dt.year.astype(int)\n",
    "    pd_data['MONTH'] = pd_data['pickup_datetime'].dt.month.astype(int)\n",
    "    pd_data['DAY'] = pd_data['pickup_datetime'].dt.day.astype(int)\n",
    "    pd_data['HOUR'] = pd_data['pickup_datetime'].dt.hour.astype(int)\n",
    "    pd_data[\"WEEK\"] = pd_data['pickup_datetime'].dt.dayofweek+1    \n",
    "    return pd_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    # remove useless columns \n",
    "    uber_dataframe = uber_dataframe.drop([\"index\", \"key\", \"fare_amount\", \"passenger_count\"], axis=1)\n",
    "    # process NAN value\n",
    "    uber_dataframe = uber_dataframe.dropna(axis=0, how='any')\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bcfd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0673c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "YEAR                 0\n",
       "MONTH                0\n",
       "DAY                  0\n",
       "HOUR                 0\n",
       "WEEK                 0\n",
       "cal_distance         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "- 1. Load and clean hourly and daily weather data\n",
    "- 2. Convert date weather data into YEAR, MONTH, DAY, HOUR and WEEK\n",
    "- 3. Remove useless columns\n",
    "- 4. Process NAN value\n",
    "- 5. Generate hourly and daily weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    pd_data = pd.read_csv(csv_file)\n",
    "    pd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\n",
    "    pd_data['YEAR'] = pd_data['DATE'].dt.year.astype(int)\n",
    "    pd_data['MONTH'] = pd_data['DATE'].dt.month.astype(int)\n",
    "    pd_data['DAY'] = pd_data['DATE'].dt.day.astype(int)\n",
    "    pd_data['HOUR'] = pd_data['DATE'].dt.hour.astype(int)    \n",
    "    pd_data[\"WEEK\"] = pd_data['DATE'].dt.dayofweek+1  \n",
    "    hour_weather = []\n",
    "    hour_weather_column = list(pd_data.columns)\n",
    "    \n",
    "    date_str = \"\"\n",
    "    for i in range(pd_data.shape[0]):\n",
    "        tmp_date_str = str(pd_data.iloc[i,:][\"YEAR\"]) + str(pd_data.iloc[i,:][\"MONTH\"]) + str(pd_data.iloc[i,:][\"DAY\"]) +  str(pd_data.iloc[i,:][\"HOUR\"])\n",
    "        if tmp_date_str == date_str:\n",
    "            continue\n",
    "        else:\n",
    "            hour_weather.append(pd_data.iloc[i,:].to_list())\n",
    "            date_str = tmp_date_str   \n",
    "    \n",
    "    final_pd = pd.DataFrame(hour_weather, columns=hour_weather_column)\n",
    "    \n",
    "    print(\"weather data : \", final_pd.head())\n",
    "    \n",
    "    # remove useless columns\n",
    "    final_pd = final_pd.drop([\"STATION\", \"ELEVATION\", \"NAME\", \"REPORT_TYPE\", \"SOURCE\"], axis=1)\n",
    "    # process NAN value\n",
    "    final_pd = final_pd.fillna(0)   \n",
    "    final_pd = final_pd.fillna(axis=0, method=\"ffill\")  \n",
    "    final_pd = final_pd.reset_index()   \n",
    "    # final_pd = final_pd.dropna(axis=1, how='any')\n",
    "    # final_pd = final_pd.dropna(axis=0, how='any')\n",
    "    return final_pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    pd_data = pd.read_csv(csv_file)\n",
    "    pd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\n",
    "    pd_data['YEAR'] = pd_data['DATE'].dt.year.astype(int)\n",
    "    pd_data['MONTH'] = pd_data['DATE'].dt.month.astype(int)\n",
    "    pd_data['DAY'] = pd_data['DATE'].dt.day.astype(int)\n",
    "    pd_data[\"WEEK\"] = pd_data['DATE'].dt.dayofweek+1  \n",
    "    date_str = \"\"\n",
    "    day_weather = []\n",
    "    day_weather_column = list(pd_data.columns)\n",
    "#     day_weather_column.remove('HOUR')\n",
    "    for i in range(pd_data.shape[0]):\n",
    "        tmp_date_str = str(pd_data.iloc[i,:][\"YEAR\"]) + str(pd_data.iloc[i,:][\"MONTH\"]) + str(pd_data.iloc[i,:][\"DAY\"])\n",
    "        if tmp_date_str == date_str:\n",
    "            continue\n",
    "        else:\n",
    "            day_weather.append(pd_data.iloc[i,:].to_list())\n",
    "            date_str = tmp_date_str \n",
    "            \n",
    "    final_pd = pd.DataFrame(day_weather, columns=day_weather_column)  \n",
    "    \n",
    "    # remove useless columns\n",
    "    final_pd = final_pd.drop([\"STATION\", \"ELEVATION\", \"NAME\", \"REPORT_TYPE\", \"SOURCE\"], axis=1)\n",
    "    # process NAN value\n",
    "    final_pd = final_pd.fillna(0)     \n",
    "    final_pd = final_pd.fillna(axis=0, method=\"ffill\") \n",
    "    final_pd = final_pd.reset_index()     \n",
    "    # final_pd = final_pd.dropna(axis=1, how='any')\n",
    "    # final_pd = final_pd.dropna(axis=0, how='any')\n",
    "    return final_pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\"2009_weather.csv\", \"2010_weather.csv\", \"2011_weather.csv\", \"2012_weather.csv\",\n",
    "                        \"2013_weather.csv\", \"2014_weather.csv\", \"2015_weather.csv\"]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Processing All Data\n",
    "\n",
    "- 1. Process taxi data, uber data, and weather data\n",
    "- 2. Post-Process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7cd53a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd_data.shape :  (12741035, 19)\n",
      "      index  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0  11589109         1  2015-01-29 18:59:06   2015-01-29 19:05:18   \n",
      "1   3063175         2  2015-01-08 22:59:42   2015-01-08 23:04:00   \n",
      "2   1904687         2  2015-01-06 08:41:30   2015-01-06 09:05:51   \n",
      "3   8983070         1  2015-01-22 14:44:21   2015-01-22 14:54:12   \n",
      "4   5969886         1  2015-01-15 14:53:41   2015-01-15 15:02:40   \n",
      "\n",
      "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "0                1           0.90           1                  N   \n",
      "1                1           1.04           1                  N   \n",
      "2                5           1.41           1                  N   \n",
      "3                1           1.10           1                  N   \n",
      "4                1           1.60           1                  N   \n",
      "\n",
      "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
      "0           262           236             1          6.0    1.0      0.5   \n",
      "1           255           256             1          5.5    0.5      0.5   \n",
      "2           237            50             1         15.0    0.0      0.5   \n",
      "3            68           164             2          7.5    0.0      0.5   \n",
      "4           263           142             2          8.5    0.0      0.5   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0        1.95           0.0                    0.3          9.75   \n",
      "1        0.00           0.0                    0.3          6.80   \n",
      "2        1.00           0.0                    0.3         16.80   \n",
      "3        0.00           0.0                    0.3          8.30   \n",
      "4        0.00           0.0                    0.3          9.30   \n",
      "\n",
      "  congestion_surcharge airport_fee  \n",
      "0                 None        None  \n",
      "1                 None        None  \n",
      "2                 None        None  \n",
      "3                 None        None  \n",
      "4                 None        None  \n",
      "sample data, pd_data.shape:  (2564, 20)\n",
      "index                       0\n",
      "VendorID                    0\n",
      "tpep_pickup_datetime        0\n",
      "tpep_dropoff_datetime       0\n",
      "passenger_count             0\n",
      "trip_distance               0\n",
      "RatecodeID                  0\n",
      "store_and_fwd_flag          0\n",
      "PULocationID                0\n",
      "DOLocationID                0\n",
      "payment_type                0\n",
      "fare_amount                 0\n",
      "extra                       0\n",
      "mta_tax                     0\n",
      "tip_amount                  0\n",
      "tolls_amount                0\n",
      "improvement_surcharge       0\n",
      "total_amount                0\n",
      "congestion_surcharge     2564\n",
      "airport_fee              2564\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lon = gdf.centroid.x\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lat = gdf.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd_data.shape :  (12442394, 19)\n",
      "      index  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0   9289781         2  2015-02-22 01:15:07   2015-02-22 01:25:27   \n",
      "1  10774457         1  2015-02-25 15:33:14   2015-02-25 15:52:12   \n",
      "2   3766936         2  2015-02-09 21:13:11   2015-02-09 21:26:31   \n",
      "3   2134190         2  2015-02-06 07:26:23   2015-02-06 07:40:21   \n",
      "4   1192544         2  2015-02-04 01:12:50   2015-02-04 01:26:10   \n",
      "\n",
      "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "0                1           2.32           1                  N   \n",
      "1                1           2.00           1                  N   \n",
      "2                6           2.63           1                  N   \n",
      "3                1           1.57           1                  N   \n",
      "4                6           3.69           1                  N   \n",
      "\n",
      "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
      "0            48           234             1          9.5    0.5      0.5   \n",
      "1           137           229             1         11.5    0.0      0.5   \n",
      "2           249           170             1         11.5    0.5      0.5   \n",
      "3           239           236             1         10.5    0.0      0.5   \n",
      "4           161           148             1         13.0    0.5      0.5   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0        2.16           0.0                    0.3         12.96   \n",
      "1        3.00           0.0                    0.3         15.30   \n",
      "2        0.00           0.0                    0.3         12.80   \n",
      "3        2.26           0.0                    0.3         13.56   \n",
      "4        4.29           0.0                    0.3         18.59   \n",
      "\n",
      "  congestion_surcharge airport_fee  \n",
      "0                 None        None  \n",
      "1                 None        None  \n",
      "2                 None        None  \n",
      "3                 None        None  \n",
      "4                 None        None  \n",
      "sample data, pd_data.shape:  (2564, 20)\n",
      "index                       0\n",
      "VendorID                    0\n",
      "tpep_pickup_datetime        0\n",
      "tpep_dropoff_datetime       0\n",
      "passenger_count             0\n",
      "trip_distance               0\n",
      "RatecodeID                  0\n",
      "store_and_fwd_flag          0\n",
      "PULocationID                0\n",
      "DOLocationID                0\n",
      "payment_type                0\n",
      "fare_amount                 0\n",
      "extra                       0\n",
      "mta_tax                     0\n",
      "tip_amount                  0\n",
      "tolls_amount                0\n",
      "improvement_surcharge       0\n",
      "total_amount                0\n",
      "congestion_surcharge     2564\n",
      "airport_fee              2564\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lon = gdf.centroid.x\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lat = gdf.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd_data.shape :  (13342951, 19)\n",
      "      index  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0   7440739         1  2015-03-18 14:38:08   2015-03-18 14:40:19   \n",
      "1   7394584         1  2015-03-18 12:14:52   2015-03-18 12:21:42   \n",
      "2   4895968         1  2015-03-12 19:40:46   2015-03-12 20:09:30   \n",
      "3  10039495         2  2015-03-24 13:41:37   2015-03-24 14:05:19   \n",
      "4  10075597         1  2015-03-24 15:52:39   2015-03-24 15:59:05   \n",
      "\n",
      "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "0                1           0.30           1                  N   \n",
      "1                1           0.80           1                  N   \n",
      "2                1           5.10           1                  N   \n",
      "3                1           2.86           1                  N   \n",
      "4                1           0.90           1                  N   \n",
      "\n",
      "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
      "0           236           236             2          3.5    0.0      0.5   \n",
      "1           186           161             1          6.0    0.0      0.5   \n",
      "2           234            97             1         22.0    1.0      0.5   \n",
      "3            90           237             1         16.0    0.0      0.5   \n",
      "4           162           229             1          6.0    0.0      0.5   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0        0.00           0.0                    0.3          4.30   \n",
      "1        1.35           0.0                    0.3          8.15   \n",
      "2        3.00           0.0                    0.3         26.80   \n",
      "3        1.00           0.0                    0.3         17.80   \n",
      "4        0.00           0.0                    0.3          6.80   \n",
      "\n",
      "  congestion_surcharge airport_fee  \n",
      "0                 None        None  \n",
      "1                 None        None  \n",
      "2                 None        None  \n",
      "3                 None        None  \n",
      "4                 None        None  \n",
      "sample data, pd_data.shape:  (2564, 20)\n",
      "index                       0\n",
      "VendorID                    0\n",
      "tpep_pickup_datetime        0\n",
      "tpep_dropoff_datetime       0\n",
      "passenger_count             0\n",
      "trip_distance               0\n",
      "RatecodeID                  0\n",
      "store_and_fwd_flag          0\n",
      "PULocationID                0\n",
      "DOLocationID                0\n",
      "payment_type                0\n",
      "fare_amount                 0\n",
      "extra                       0\n",
      "mta_tax                     0\n",
      "tip_amount                  0\n",
      "tolls_amount                0\n",
      "improvement_surcharge       0\n",
      "total_amount                0\n",
      "congestion_surcharge     2564\n",
      "airport_fee              2564\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lon = gdf.centroid.x\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lat = gdf.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd_data.shape :  (13063758, 19)\n",
      "      index  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0  11669478         1  2015-04-27 19:08:27   2015-04-27 19:15:57   \n",
      "1   7519259         1  2015-04-18 12:36:26   2015-04-18 12:46:05   \n",
      "2   4289636         1  2015-04-10 23:13:08   2015-04-10 23:31:05   \n",
      "3   4798511         2  2015-04-12 00:25:03   2015-04-12 00:37:12   \n",
      "4  12999994         1  2015-04-30 21:24:26   2015-04-30 21:33:24   \n",
      "\n",
      "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "0                2           1.30           1                  N   \n",
      "1                1           2.40           1                  N   \n",
      "2                1           1.90           1                  N   \n",
      "3                2           2.35           1                  N   \n",
      "4                1           2.10           1                  N   \n",
      "\n",
      "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
      "0           137            90             2          7.0    1.0      0.5   \n",
      "1            13           246             2         10.0    0.0      0.5   \n",
      "2            68            43             1         13.0    0.5      0.5   \n",
      "3           142           236             2         11.0    0.5      0.5   \n",
      "4           161           113             1          9.0    0.5      0.5   \n",
      "\n",
      "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0        0.00           0.0                    0.3          8.80   \n",
      "1        0.00           0.0                    0.3         10.80   \n",
      "2        2.85           0.0                    0.3         17.15   \n",
      "3        0.00           0.0                    0.3         12.30   \n",
      "4        2.05           0.0                    0.3         12.35   \n",
      "\n",
      "  congestion_surcharge airport_fee  \n",
      "0                 None        None  \n",
      "1                 None        None  \n",
      "2                 None        None  \n",
      "3                 None        None  \n",
      "4                 None        None  \n",
      "sample data, pd_data.shape:  (2564, 20)\n",
      "index                       0\n",
      "VendorID                    0\n",
      "tpep_pickup_datetime        0\n",
      "tpep_dropoff_datetime       0\n",
      "passenger_count             0\n",
      "trip_distance               0\n",
      "RatecodeID                  0\n",
      "store_and_fwd_flag          0\n",
      "PULocationID                0\n",
      "DOLocationID                0\n",
      "payment_type                0\n",
      "fare_amount                 0\n",
      "extra                       0\n",
      "mta_tax                     0\n",
      "tip_amount                  0\n",
      "tolls_amount                0\n",
      "improvement_surcharge       0\n",
      "total_amount                0\n",
      "congestion_surcharge     2564\n",
      "airport_fee              2564\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lon = gdf.centroid.x\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/219217041.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lat = gdf.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_0                    0\n",
      "index                      0\n",
      "VendorID                   0\n",
      "tpep_pickup_datetime       0\n",
      "tpep_dropoff_datetime      0\n",
      "passenger_count            0\n",
      "trip_distance              0\n",
      "RatecodeID                 0\n",
      "store_and_fwd_flag         0\n",
      "PULocationID               0\n",
      "DOLocationID               0\n",
      "payment_type               0\n",
      "fare_amount                0\n",
      "extra                      0\n",
      "mta_tax                    0\n",
      "tip_amount                 0\n",
      "tolls_amount               0\n",
      "improvement_surcharge      0\n",
      "total_amount               0\n",
      "pickup_longitude         179\n",
      "pickup_latitude          179\n",
      "dropoff_longitude        210\n",
      "dropoff_latitude         210\n",
      "YEAR                       0\n",
      "MONTH                      0\n",
      "DAY                        0\n",
      "HOUR                       0\n",
      "WEEK                       0\n",
      "cal_distance             226\n",
      "dtype: int64\n",
      "(10256, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2009-01-01 00:51:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2009-01-01 01:51:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2009-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2009-01-01 03:51:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2009-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE SOURCE HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.01   \n",
      "1  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.03   \n",
      "2  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.07   \n",
      "3  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.09   \n",
      "4  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.12   \n",
      "\n",
      "  HourlyDewPointTemperature  ...  BackupEquipment BackupLatitude  \\\n",
      "0                       3.0  ...        SNOWBOARD            NaN   \n",
      "1                       3.0  ...        SNOWBOARD            NaN   \n",
      "2                       3.0  ...        SNOWBOARD            NaN   \n",
      "3                       3.0  ...        SNOWBOARD            NaN   \n",
      "4                       3.0  ...        SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR  MONTH DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO                2006/9/18  2009      1   1   \n",
      "1             NaN  CENTRAL PARK ZOO                2006/9/18  2009      1   1   \n",
      "2             NaN  CENTRAL PARK ZOO                2006/9/18  2009      1   1   \n",
      "3             NaN  CENTRAL PARK ZOO                2006/9/18  2009      1   1   \n",
      "4             NaN  CENTRAL PARK ZOO                2006/9/18  2009      1   1   \n",
      "\n",
      "   HOUR  WEEK  \n",
      "0     0     4  \n",
      "1     1     4  \n",
      "2     2     4  \n",
      "3     3     4  \n",
      "4     4     4  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2010-01-01 00:30:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2010-01-01 01:09:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2010-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2010-01-01 03:00:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2010-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE SOURCE HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       FM-16      4                  30.01   \n",
      "1  NY CITY CENTRAL PARK, NY US       FM-16      4                  29.99   \n",
      "2  NY CITY CENTRAL PARK, NY US       AUTO       4                  29.99   \n",
      "3  NY CITY CENTRAL PARK, NY US       FM-15      4                  29.99   \n",
      "4  NY CITY CENTRAL PARK, NY US       AUTO       4                  29.97   \n",
      "\n",
      "  HourlyDewPointTemperature  ... BackupEquipment BackupLatitude  \\\n",
      "0                        32  ...       SNOWBOARD            NaN   \n",
      "1                        32  ...       SNOWBOARD            NaN   \n",
      "2                        34  ...       SNOWBOARD            NaN   \n",
      "3                        34  ...       SNOWBOARD            NaN   \n",
      "4                        34  ...       SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR MONTH DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO               2006-09-18  2010     1   1   \n",
      "1             NaN  CENTRAL PARK ZOO               2006-09-18  2010     1   1   \n",
      "2             NaN  CENTRAL PARK ZOO               2006-09-18  2010     1   1   \n",
      "3             NaN  CENTRAL PARK ZOO               2006-09-18  2010     1   1   \n",
      "4             NaN  CENTRAL PARK ZOO               2006-09-18  2010     1   1   \n",
      "\n",
      "   HOUR  WEEK  \n",
      "0     0     5  \n",
      "1     1     5  \n",
      "2     2     5  \n",
      "3     3     5  \n",
      "4     4     5  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2011-01-01 00:51:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2011-01-01 01:51:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2011-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2011-01-01 03:51:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2011-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE SOURCE HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.15   \n",
      "1  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.14   \n",
      "2  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.14   \n",
      "3  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.14   \n",
      "4  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.13   \n",
      "\n",
      "  HourlyDewPointTemperature  ... BackupEquipment BackupLatitude  \\\n",
      "0                        28  ...       SNOWBOARD            NaN   \n",
      "1                        28  ...       SNOWBOARD            NaN   \n",
      "2                        28  ...       SNOWBOARD            NaN   \n",
      "3                        30  ...       SNOWBOARD            NaN   \n",
      "4                        28  ...       SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR MONTH DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO               2006-09-18  2011     1   1   \n",
      "1             NaN  CENTRAL PARK ZOO               2006-09-18  2011     1   1   \n",
      "2             NaN  CENTRAL PARK ZOO               2006-09-18  2011     1   1   \n",
      "3             NaN  CENTRAL PARK ZOO               2006-09-18  2011     1   1   \n",
      "4             NaN  CENTRAL PARK ZOO               2006-09-18  2011     1   1   \n",
      "\n",
      "   HOUR  WEEK  \n",
      "0     0     6  \n",
      "1     1     6  \n",
      "2     2     6  \n",
      "3     3     6  \n",
      "4     4     6  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2012-01-01 00:51:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2012-01-01 01:51:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2012-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2012-01-01 03:51:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2012-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE SOURCE HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.05   \n",
      "1  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.07   \n",
      "2  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.08   \n",
      "3  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.06   \n",
      "4  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.07   \n",
      "\n",
      "  HourlyDewPointTemperature  ... BackupEquipment BackupLatitude  \\\n",
      "0                        37  ...       SNOWBOARD            NaN   \n",
      "1                        37  ...       SNOWBOARD            NaN   \n",
      "2                        37  ...       SNOWBOARD            NaN   \n",
      "3                        37  ...       SNOWBOARD            NaN   \n",
      "4                        37  ...       SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR MONTH DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO               2006-09-18  2012     1   1   \n",
      "1             NaN  CENTRAL PARK ZOO               2006-09-18  2012     1   1   \n",
      "2             NaN  CENTRAL PARK ZOO               2006-09-18  2012     1   1   \n",
      "3             NaN  CENTRAL PARK ZOO               2006-09-18  2012     1   1   \n",
      "4             NaN  CENTRAL PARK ZOO               2006-09-18  2012     1   1   \n",
      "\n",
      "  HOUR WEEK  \n",
      "0    0    7  \n",
      "1    1    7  \n",
      "2    2    7  \n",
      "3    3    7  \n",
      "4    4    7  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (17,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2013-01-01 00:51:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2013-01-01 01:51:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2013-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2013-01-01 03:51:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2013-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE  SOURCE HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       FM-15       7                  29.89   \n",
      "1  NY CITY CENTRAL PARK, NY US       FM-15       7                  29.90   \n",
      "2  NY CITY CENTRAL PARK, NY US       FM-15       7                  29.90   \n",
      "3  NY CITY CENTRAL PARK, NY US       FM-15       7                  29.91   \n",
      "4  NY CITY CENTRAL PARK, NY US       FM-15       7                  29.90   \n",
      "\n",
      "   HourlyDewPointTemperature  ...  BackupEquipment BackupLatitude  \\\n",
      "0                       24.0  ...        SNOWBOARD            NaN   \n",
      "1                       26.0  ...        SNOWBOARD            NaN   \n",
      "2                       27.0  ...        SNOWBOARD            NaN   \n",
      "3                       27.0  ...        SNOWBOARD            NaN   \n",
      "4                       27.0  ...        SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR MONTH DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO               2006-09-18  2013     1   1   \n",
      "1             NaN  CENTRAL PARK ZOO               2006-09-18  2013     1   1   \n",
      "2             NaN  CENTRAL PARK ZOO               2006-09-18  2013     1   1   \n",
      "3             NaN  CENTRAL PARK ZOO               2006-09-18  2013     1   1   \n",
      "4             NaN  CENTRAL PARK ZOO               2006-09-18  2013     1   1   \n",
      "\n",
      "  HOUR WEEK  \n",
      "0    0    2  \n",
      "1    1    2  \n",
      "2    2    2  \n",
      "3    3    2  \n",
      "4    4    2  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (17,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (8,9,17,18,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2014-01-01 00:51:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2014-01-01 01:51:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2014-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2014-01-01 03:51:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2014-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE  SOURCE HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       FM-15       7                  30.30   \n",
      "1  NY CITY CENTRAL PARK, NY US       FM-15       7                  30.33   \n",
      "2  NY CITY CENTRAL PARK, NY US       FM-15       7                  30.35   \n",
      "3  NY CITY CENTRAL PARK, NY US       FM-15       7                  30.36   \n",
      "4  NY CITY CENTRAL PARK, NY US       FM-15       7                  30.37   \n",
      "\n",
      "  HourlyDewPointTemperature  ...  BackupEquipment BackupLatitude  \\\n",
      "0                         6  ...        SNOWBOARD            NaN   \n",
      "1                         5  ...        SNOWBOARD            NaN   \n",
      "2                         6  ...        SNOWBOARD            NaN   \n",
      "3                         6  ...        SNOWBOARD            NaN   \n",
      "4                         7  ...        SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR MONTH DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO               2006-09-18  2014     1   1   \n",
      "1             NaN  CENTRAL PARK ZOO               2006-09-18  2014     1   1   \n",
      "2             NaN  CENTRAL PARK ZOO               2006-09-18  2014     1   1   \n",
      "3             NaN  CENTRAL PARK ZOO               2006-09-18  2014     1   1   \n",
      "4             NaN  CENTRAL PARK ZOO               2006-09-18  2014     1   1   \n",
      "\n",
      "  HOUR WEEK  \n",
      "0    0    3  \n",
      "1    1    3  \n",
      "2    2    3  \n",
      "3    3    3  \n",
      "4    4    3  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (8,9,17,18,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:11: DtypeWarning: Columns (10,41,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather data :         STATION                DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "0  72505394728 2015-01-01 00:51:00  40.77898  -73.96925       42.7   \n",
      "1  72505394728 2015-01-01 01:51:00  40.77898  -73.96925       42.7   \n",
      "2  72505394728 2015-01-01 02:51:00  40.77898  -73.96925       42.7   \n",
      "3  72505394728 2015-01-01 03:51:00  40.77898  -73.96925       42.7   \n",
      "4  72505394728 2015-01-01 04:51:00  40.77898  -73.96925       42.7   \n",
      "\n",
      "                          NAME REPORT_TYPE  SOURCE  HourlyAltimeterSetting  \\\n",
      "0  NY CITY CENTRAL PARK, NY US       FM-15       7                   30.16   \n",
      "1  NY CITY CENTRAL PARK, NY US       FM-15       7                   30.16   \n",
      "2  NY CITY CENTRAL PARK, NY US       FM-15       7                   30.16   \n",
      "3  NY CITY CENTRAL PARK, NY US       FM-15       7                   30.14   \n",
      "4  NY CITY CENTRAL PARK, NY US       FM-15       7                   30.15   \n",
      "\n",
      "   HourlyDewPointTemperature  ... BackupEquipment BackupLatitude  \\\n",
      "0                        8.0  ...       SNOWBOARD            NaN   \n",
      "1                       10.0  ...       SNOWBOARD            NaN   \n",
      "2                        9.0  ...       SNOWBOARD            NaN   \n",
      "3                        7.0  ...       SNOWBOARD            NaN   \n",
      "4                        6.0  ...       SNOWBOARD            NaN   \n",
      "\n",
      "  BackupLongitude        BackupName  WindEquipmentChangeDate  YEAR MONTH  DAY  \\\n",
      "0             NaN  CENTRAL PARK ZOO               2006-09-18  2015     1    1   \n",
      "1             NaN  CENTRAL PARK ZOO               2006-09-18  2015     1    1   \n",
      "2             NaN  CENTRAL PARK ZOO               2006-09-18  2015     1    1   \n",
      "3             NaN  CENTRAL PARK ZOO               2006-09-18  2015     1    1   \n",
      "4             NaN  CENTRAL PARK ZOO               2006-09-18  2015     1    1   \n",
      "\n",
      "   HOUR WEEK  \n",
      "0     0    4  \n",
      "1     1    4  \n",
      "2     2    4  \n",
      "3     3    4  \n",
      "4     4    4  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/gdqmgyw56pnfmplfzw2m2sx80000gn/T/ipykernel_65380/3016219600.py:12: DtypeWarning: Columns (10,41,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  daily_dataframe = clean_month_weather_data_daily(csv_file)\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9be8476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10256, 29)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67a98dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi data:  (10256, 29)\n",
      "   level_0     index  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0        0  11589109         1  2015-01-29 18:59:06   2015-01-29 19:05:18   \n",
      "1        1   3063175         2  2015-01-08 22:59:42   2015-01-08 23:04:00   \n",
      "2        2   1904687         2  2015-01-06 08:41:30   2015-01-06 09:05:51   \n",
      "3        3   8983070         1  2015-01-22 14:44:21   2015-01-22 14:54:12   \n",
      "4        4   5969886         1  2015-01-15 14:53:41   2015-01-15 15:02:40   \n",
      "\n",
      "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "0                1           0.90           1                  N   \n",
      "1                1           1.04           1                  N   \n",
      "2                5           1.41           1                  N   \n",
      "3                1           1.10           1                  N   \n",
      "4                1           1.60           1                  N   \n",
      "\n",
      "   PULocationID  ...  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0           262  ...        -73.946510        40.775932         -73.957012   \n",
      "1           255  ...        -73.957418        40.718804         -73.959905   \n",
      "2           237  ...        -73.965635        40.768615         -73.995135   \n",
      "3            68  ...        -73.999917        40.748428         -73.985156   \n",
      "4           263  ...        -73.951010        40.778766         -73.981532   \n",
      "\n",
      "   dropoff_latitude  YEAR  MONTH  DAY  HOUR  WEEK  cal_distance  \n",
      "0         40.780436  2015      1   29    18     4      1.017352  \n",
      "1         40.710880  2015      1    8    22     4      0.906701  \n",
      "2         40.766238  2015      1    6     8     2      2.501233  \n",
      "3         40.748575  2015      1   22    14     4      1.244959  \n",
      "4         40.773633  2015      1   15    14     4      2.635661  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "uber_data:  (199999, 11)\n",
      "            pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
      "0 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
      "1 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
      "2 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
      "3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
      "4 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
      "\n",
      "   dropoff_longitude  dropoff_latitude  YEAR  MONTH  DAY  HOUR  WEEK  \\\n",
      "0         -73.999512         40.723217  2015      5    7    19     4   \n",
      "1         -73.994710         40.750325  2009      7   17    20     5   \n",
      "2         -73.962565         40.772647  2009      8   24    21     1   \n",
      "3         -73.965316         40.803349  2009      6   26     8     5   \n",
      "4         -73.973082         40.761247  2014      8   28    17     4   \n",
      "\n",
      "   cal_distance  \n",
      "0      1.685209  \n",
      "1      2.460343  \n",
      "2      5.042019  \n",
      "3      1.663545  \n",
      "4      4.480464  \n",
      " hourly weather:  (60458, 124)\n",
      "   index                DATE  LATITUDE  LONGITUDE HourlyAltimeterSetting  \\\n",
      "0      0 2009-01-01 00:51:00  40.77898  -73.96925                  30.01   \n",
      "1      1 2009-01-01 01:51:00  40.77898  -73.96925                  30.03   \n",
      "2      2 2009-01-01 02:51:00  40.77898  -73.96925                  30.07   \n",
      "3      3 2009-01-01 03:51:00  40.77898  -73.96925                  30.09   \n",
      "4      4 2009-01-01 04:51:00  40.77898  -73.96925                  30.12   \n",
      "\n",
      "  HourlyDewPointTemperature HourlyDryBulbTemperature HourlyPrecipitation  \\\n",
      "0                       3.0                     18.0                   0   \n",
      "1                       3.0                     18.0                   0   \n",
      "2                       3.0                     18.0                   0   \n",
      "3                       3.0                     18.0                   0   \n",
      "4                       3.0                     18.0                   0   \n",
      "\n",
      "  HourlyPresentWeatherType HourlyPressureChange  ...  BackupEquipment  \\\n",
      "0                        0                -0.04  ...        SNOWBOARD   \n",
      "1                        0                    0  ...        SNOWBOARD   \n",
      "2                        0                    0  ...        SNOWBOARD   \n",
      "3                        0                -0.07  ...        SNOWBOARD   \n",
      "4                        0                    0  ...        SNOWBOARD   \n",
      "\n",
      "   BackupLatitude BackupLongitude        BackupName WindEquipmentChangeDate  \\\n",
      "0             0.0             0.0  CENTRAL PARK ZOO               2006/9/18   \n",
      "1             0.0             0.0  CENTRAL PARK ZOO               2006/9/18   \n",
      "2             0.0             0.0  CENTRAL PARK ZOO               2006/9/18   \n",
      "3             0.0             0.0  CENTRAL PARK ZOO               2006/9/18   \n",
      "4             0.0             0.0  CENTRAL PARK ZOO               2006/9/18   \n",
      "\n",
      "   YEAR  MONTH DAY  HOUR  WEEK  \n",
      "0  2009      1   1     0     4  \n",
      "1  2009      1   1     1     4  \n",
      "2  2009      1   1     2     4  \n",
      "3  2009      1   1     3     4  \n",
      "4  2009      1   1     4     4  \n",
      "\n",
      "[5 rows x 124 columns]\n",
      "daily weather:  (2551, 123)\n",
      "   index                DATE  LATITUDE  LONGITUDE HourlyAltimeterSetting  \\\n",
      "0      0 2009-01-01 00:51:00  40.77898  -73.96925                  30.01   \n",
      "1      1 2009-01-02 00:51:00  40.77898  -73.96925                   30.2   \n",
      "2      2 2009-01-03 00:51:00  40.77898  -73.96925                  29.78   \n",
      "3      3 2009-01-04 00:51:00  40.77898  -73.96925                  30.07   \n",
      "4      4 2009-01-05 00:51:00  40.77898  -73.96925                  29.97   \n",
      "\n",
      "  HourlyDewPointTemperature HourlyDryBulbTemperature HourlyPrecipitation  \\\n",
      "0                       3.0                     18.0                   0   \n",
      "1                       1.0                     25.0                   0   \n",
      "2                      21.0                     32.0                   0   \n",
      "3                       9.0                     28.0                   0   \n",
      "4                      14.0                     39.0                   0   \n",
      "\n",
      "  HourlyPresentWeatherType HourlyPressureChange  ...  BackupElevation  \\\n",
      "0                        0                -0.04  ...              0.0   \n",
      "1                        0                 0.06  ...              0.0   \n",
      "2                        0                -0.02  ...              0.0   \n",
      "3                        0                    0  ...              0.0   \n",
      "4                        0                 0.06  ...              0.0   \n",
      "\n",
      "   BackupEquipment BackupLatitude BackupLongitude        BackupName  \\\n",
      "0        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
      "1        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
      "2        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
      "3        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
      "4        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
      "\n",
      "  WindEquipmentChangeDate  YEAR MONTH  DAY  WEEK  \n",
      "0               2006/9/18  2009     1    1     4  \n",
      "1               2006/9/18  2009     1    2     5  \n",
      "2               2006/9/18  2009     1    3     6  \n",
      "3               2006/9/18  2009     1    4     7  \n",
      "4               2006/9/18  2009     1    5     1  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"taxi data: \", taxi_data.shape)\n",
    "print(taxi_data.head())\n",
    "\n",
    "print(\"uber_data: \", uber_data.shape)\n",
    "print(uber_data.head())\n",
    "\n",
    "print(\" hourly weather: \", hourly_weather_data.shape)\n",
    "\n",
    "print(hourly_weather_data.head())\n",
    "\n",
    "print(\"daily weather: \", daily_weather_data.shape)\n",
    "print(daily_weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "556a63cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'level_0': 0,\n",
       " 'index': 0,\n",
       " 'VendorID': 0,\n",
       " 'tpep_pickup_datetime': 0,\n",
       " 'tpep_dropoff_datetime': 0,\n",
       " 'passenger_count': 0,\n",
       " 'trip_distance': 0,\n",
       " 'RatecodeID': 0,\n",
       " 'store_and_fwd_flag': 0,\n",
       " 'PULocationID': 0,\n",
       " 'DOLocationID': 0,\n",
       " 'payment_type': 0,\n",
       " 'fare_amount': 0,\n",
       " 'extra': 0,\n",
       " 'mta_tax': 0,\n",
       " 'tip_amount': 0,\n",
       " 'tolls_amount': 0,\n",
       " 'improvement_surcharge': 0,\n",
       " 'total_amount': 0,\n",
       " 'pickup_longitude': 179,\n",
       " 'pickup_latitude': 179,\n",
       " 'dropoff_longitude': 210,\n",
       " 'dropoff_latitude': 210,\n",
       " 'YEAR': 0,\n",
       " 'MONTH': 0,\n",
       " 'DAY': 0,\n",
       " 'HOUR': 0,\n",
       " 'WEEK': 0,\n",
       " 'cal_distance': 226}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(taxi_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56cc59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = taxi_data.fillna(axis=0, method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d955a168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                  0\n",
       "index                    0\n",
       "VendorID                 0\n",
       "tpep_pickup_datetime     0\n",
       "tpep_dropoff_datetime    0\n",
       "passenger_count          0\n",
       "trip_distance            0\n",
       "RatecodeID               0\n",
       "store_and_fwd_flag       0\n",
       "PULocationID             0\n",
       "DOLocationID             0\n",
       "payment_type             0\n",
       "fare_amount              0\n",
       "extra                    0\n",
       "mta_tax                  0\n",
       "tip_amount               0\n",
       "tolls_amount             0\n",
       "improvement_surcharge    0\n",
       "total_amount             0\n",
       "pickup_longitude         0\n",
       "pickup_latitude          0\n",
       "dropoff_longitude        0\n",
       "dropoff_latitude         0\n",
       "YEAR                     0\n",
       "MONTH                    0\n",
       "DAY                      0\n",
       "HOUR                     0\n",
       "WEEK                     0\n",
       "cal_distance             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d624019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'DATE': 0,\n",
       " 'LATITUDE': 0,\n",
       " 'LONGITUDE': 0,\n",
       " 'HourlyAltimeterSetting': 0,\n",
       " 'HourlyDewPointTemperature': 0,\n",
       " 'HourlyDryBulbTemperature': 0,\n",
       " 'HourlyPrecipitation': 0,\n",
       " 'HourlyPresentWeatherType': 0,\n",
       " 'HourlyPressureChange': 0,\n",
       " 'HourlyPressureTendency': 0,\n",
       " 'HourlyRelativeHumidity': 0,\n",
       " 'HourlySkyConditions': 0,\n",
       " 'HourlySeaLevelPressure': 0,\n",
       " 'HourlyStationPressure': 0,\n",
       " 'HourlyVisibility': 0,\n",
       " 'HourlyWetBulbTemperature': 0,\n",
       " 'HourlyWindDirection': 0,\n",
       " 'HourlyWindGustSpeed': 0,\n",
       " 'HourlyWindSpeed': 0,\n",
       " 'Sunrise': 0,\n",
       " 'Sunset': 0,\n",
       " 'DailyAverageDewPointTemperature': 0,\n",
       " 'DailyAverageDryBulbTemperature': 0,\n",
       " 'DailyAverageRelativeHumidity': 0,\n",
       " 'DailyAverageSeaLevelPressure': 0,\n",
       " 'DailyAverageStationPressure': 0,\n",
       " 'DailyAverageWetBulbTemperature': 0,\n",
       " 'DailyAverageWindSpeed': 0,\n",
       " 'DailyCoolingDegreeDays': 0,\n",
       " 'DailyDepartureFromNormalAverageTemperature': 0,\n",
       " 'DailyHeatingDegreeDays': 0,\n",
       " 'DailyMaximumDryBulbTemperature': 0,\n",
       " 'DailyMinimumDryBulbTemperature': 0,\n",
       " 'DailyPeakWindDirection': 0,\n",
       " 'DailyPeakWindSpeed': 0,\n",
       " 'DailyPrecipitation': 0,\n",
       " 'DailySnowDepth': 0,\n",
       " 'DailySnowfall': 0,\n",
       " 'DailySustainedWindDirection': 0,\n",
       " 'DailySustainedWindSpeed': 0,\n",
       " 'DailyWeather': 0,\n",
       " 'MonthlyAverageRH': 0,\n",
       " 'MonthlyDaysWithGT001Precip': 0,\n",
       " 'MonthlyDaysWithGT010Precip': 0,\n",
       " 'MonthlyDaysWithGT32Temp': 0,\n",
       " 'MonthlyDaysWithGT90Temp': 0,\n",
       " 'MonthlyDaysWithLT0Temp': 0,\n",
       " 'MonthlyDaysWithLT32Temp': 0,\n",
       " 'MonthlyDepartureFromNormalAverageTemperature': 0,\n",
       " 'MonthlyDepartureFromNormalCoolingDegreeDays': 0,\n",
       " 'MonthlyDepartureFromNormalHeatingDegreeDays': 0,\n",
       " 'MonthlyDepartureFromNormalMaximumTemperature': 0,\n",
       " 'MonthlyDepartureFromNormalMinimumTemperature': 0,\n",
       " 'MonthlyDepartureFromNormalPrecipitation': 0,\n",
       " 'MonthlyDewpointTemperature': 0,\n",
       " 'MonthlyGreatestPrecip': 0,\n",
       " 'MonthlyGreatestPrecipDate': 0,\n",
       " 'MonthlyGreatestSnowDepth': 0,\n",
       " 'MonthlyGreatestSnowDepthDate': 0,\n",
       " 'MonthlyGreatestSnowfall': 0,\n",
       " 'MonthlyGreatestSnowfallDate': 0,\n",
       " 'MonthlyMaxSeaLevelPressureValue': 0,\n",
       " 'MonthlyMaxSeaLevelPressureValueDate': 0,\n",
       " 'MonthlyMaxSeaLevelPressureValueTime': 0,\n",
       " 'MonthlyMaximumTemperature': 0,\n",
       " 'MonthlyMeanTemperature': 0,\n",
       " 'MonthlyMinSeaLevelPressureValue': 0,\n",
       " 'MonthlyMinSeaLevelPressureValueDate': 0,\n",
       " 'MonthlyMinSeaLevelPressureValueTime': 0,\n",
       " 'MonthlyMinimumTemperature': 0,\n",
       " 'MonthlySeaLevelPressure': 0,\n",
       " 'MonthlyStationPressure': 0,\n",
       " 'MonthlyTotalLiquidPrecipitation': 0,\n",
       " 'MonthlyTotalSnowfall': 0,\n",
       " 'MonthlyWetBulb': 0,\n",
       " 'AWND': 0,\n",
       " 'CDSD': 0,\n",
       " 'CLDD': 0,\n",
       " 'DSNW': 0,\n",
       " 'HDSD': 0,\n",
       " 'HTDD': 0,\n",
       " 'NormalsCoolingDegreeDay': 0,\n",
       " 'NormalsHeatingDegreeDay': 0,\n",
       " 'ShortDurationEndDate005': 0,\n",
       " 'ShortDurationEndDate010': 0,\n",
       " 'ShortDurationEndDate015': 0,\n",
       " 'ShortDurationEndDate020': 0,\n",
       " 'ShortDurationEndDate030': 0,\n",
       " 'ShortDurationEndDate045': 0,\n",
       " 'ShortDurationEndDate060': 0,\n",
       " 'ShortDurationEndDate080': 0,\n",
       " 'ShortDurationEndDate100': 0,\n",
       " 'ShortDurationEndDate120': 0,\n",
       " 'ShortDurationEndDate150': 0,\n",
       " 'ShortDurationEndDate180': 0,\n",
       " 'ShortDurationPrecipitationValue005': 0,\n",
       " 'ShortDurationPrecipitationValue010': 0,\n",
       " 'ShortDurationPrecipitationValue015': 0,\n",
       " 'ShortDurationPrecipitationValue020': 0,\n",
       " 'ShortDurationPrecipitationValue030': 0,\n",
       " 'ShortDurationPrecipitationValue045': 0,\n",
       " 'ShortDurationPrecipitationValue060': 0,\n",
       " 'ShortDurationPrecipitationValue080': 0,\n",
       " 'ShortDurationPrecipitationValue100': 0,\n",
       " 'ShortDurationPrecipitationValue120': 0,\n",
       " 'ShortDurationPrecipitationValue150': 0,\n",
       " 'ShortDurationPrecipitationValue180': 0,\n",
       " 'REM': 0,\n",
       " 'BackupDirection': 0,\n",
       " 'BackupDistance': 0,\n",
       " 'BackupDistanceUnit': 0,\n",
       " 'BackupElements': 0,\n",
       " 'BackupElevation': 0,\n",
       " 'BackupEquipment': 0,\n",
       " 'BackupLatitude': 0,\n",
       " 'BackupLongitude': 0,\n",
       " 'BackupName': 0,\n",
       " 'WindEquipmentChangeDate': 0,\n",
       " 'YEAR': 0,\n",
       " 'MONTH': 0,\n",
       " 'DAY': 0,\n",
       " 'HOUR': 0,\n",
       " 'WEEK': 0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(hourly_weather_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e49a988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'DATE',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'HourlyAltimeterSetting',\n",
       " 'HourlyDewPointTemperature',\n",
       " 'HourlyDryBulbTemperature',\n",
       " 'HourlyPrecipitation',\n",
       " 'HourlyPresentWeatherType',\n",
       " 'HourlyPressureChange',\n",
       " 'HourlyPressureTendency',\n",
       " 'HourlyRelativeHumidity',\n",
       " 'HourlySkyConditions',\n",
       " 'HourlySeaLevelPressure',\n",
       " 'HourlyStationPressure',\n",
       " 'HourlyVisibility',\n",
       " 'HourlyWetBulbTemperature',\n",
       " 'HourlyWindDirection',\n",
       " 'HourlyWindGustSpeed',\n",
       " 'HourlyWindSpeed',\n",
       " 'Sunrise',\n",
       " 'Sunset',\n",
       " 'DailyAverageDewPointTemperature',\n",
       " 'DailyAverageDryBulbTemperature',\n",
       " 'DailyAverageRelativeHumidity',\n",
       " 'DailyAverageSeaLevelPressure',\n",
       " 'DailyAverageStationPressure',\n",
       " 'DailyAverageWetBulbTemperature',\n",
       " 'DailyAverageWindSpeed',\n",
       " 'DailyCoolingDegreeDays',\n",
       " 'DailyDepartureFromNormalAverageTemperature',\n",
       " 'DailyHeatingDegreeDays',\n",
       " 'DailyMaximumDryBulbTemperature',\n",
       " 'DailyMinimumDryBulbTemperature',\n",
       " 'DailyPeakWindDirection',\n",
       " 'DailyPeakWindSpeed',\n",
       " 'DailyPrecipitation',\n",
       " 'DailySnowDepth',\n",
       " 'DailySnowfall',\n",
       " 'DailySustainedWindDirection',\n",
       " 'DailySustainedWindSpeed',\n",
       " 'DailyWeather',\n",
       " 'MonthlyAverageRH',\n",
       " 'MonthlyDaysWithGT001Precip',\n",
       " 'MonthlyDaysWithGT010Precip',\n",
       " 'MonthlyDaysWithGT32Temp',\n",
       " 'MonthlyDaysWithGT90Temp',\n",
       " 'MonthlyDaysWithLT0Temp',\n",
       " 'MonthlyDaysWithLT32Temp',\n",
       " 'MonthlyDepartureFromNormalAverageTemperature',\n",
       " 'MonthlyDepartureFromNormalCoolingDegreeDays',\n",
       " 'MonthlyDepartureFromNormalHeatingDegreeDays',\n",
       " 'MonthlyDepartureFromNormalMaximumTemperature',\n",
       " 'MonthlyDepartureFromNormalMinimumTemperature',\n",
       " 'MonthlyDepartureFromNormalPrecipitation',\n",
       " 'MonthlyDewpointTemperature',\n",
       " 'MonthlyGreatestPrecip',\n",
       " 'MonthlyGreatestPrecipDate',\n",
       " 'MonthlyGreatestSnowDepth',\n",
       " 'MonthlyGreatestSnowDepthDate',\n",
       " 'MonthlyGreatestSnowfall',\n",
       " 'MonthlyGreatestSnowfallDate',\n",
       " 'MonthlyMaxSeaLevelPressureValue',\n",
       " 'MonthlyMaxSeaLevelPressureValueDate',\n",
       " 'MonthlyMaxSeaLevelPressureValueTime',\n",
       " 'MonthlyMaximumTemperature',\n",
       " 'MonthlyMeanTemperature',\n",
       " 'MonthlyMinSeaLevelPressureValue',\n",
       " 'MonthlyMinSeaLevelPressureValueDate',\n",
       " 'MonthlyMinSeaLevelPressureValueTime',\n",
       " 'MonthlyMinimumTemperature',\n",
       " 'MonthlySeaLevelPressure',\n",
       " 'MonthlyStationPressure',\n",
       " 'MonthlyTotalLiquidPrecipitation',\n",
       " 'MonthlyTotalSnowfall',\n",
       " 'MonthlyWetBulb',\n",
       " 'AWND',\n",
       " 'CDSD',\n",
       " 'CLDD',\n",
       " 'DSNW',\n",
       " 'HDSD',\n",
       " 'HTDD',\n",
       " 'NormalsCoolingDegreeDay',\n",
       " 'NormalsHeatingDegreeDay',\n",
       " 'ShortDurationEndDate005',\n",
       " 'ShortDurationEndDate010',\n",
       " 'ShortDurationEndDate015',\n",
       " 'ShortDurationEndDate020',\n",
       " 'ShortDurationEndDate030',\n",
       " 'ShortDurationEndDate045',\n",
       " 'ShortDurationEndDate060',\n",
       " 'ShortDurationEndDate080',\n",
       " 'ShortDurationEndDate100',\n",
       " 'ShortDurationEndDate120',\n",
       " 'ShortDurationEndDate150',\n",
       " 'ShortDurationEndDate180',\n",
       " 'ShortDurationPrecipitationValue005',\n",
       " 'ShortDurationPrecipitationValue010',\n",
       " 'ShortDurationPrecipitationValue015',\n",
       " 'ShortDurationPrecipitationValue020',\n",
       " 'ShortDurationPrecipitationValue030',\n",
       " 'ShortDurationPrecipitationValue045',\n",
       " 'ShortDurationPrecipitationValue060',\n",
       " 'ShortDurationPrecipitationValue080',\n",
       " 'ShortDurationPrecipitationValue100',\n",
       " 'ShortDurationPrecipitationValue120',\n",
       " 'ShortDurationPrecipitationValue150',\n",
       " 'ShortDurationPrecipitationValue180',\n",
       " 'REM',\n",
       " 'BackupDirection',\n",
       " 'BackupDistance',\n",
       " 'BackupDistanceUnit',\n",
       " 'BackupElements',\n",
       " 'BackupElevation',\n",
       " 'BackupEquipment',\n",
       " 'BackupLatitude',\n",
       " 'BackupLongitude',\n",
       " 'BackupName',\n",
       " 'WindEquipmentChangeDate',\n",
       " 'YEAR',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'HOUR',\n",
       " 'WEEK']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hourly_weather_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38b99860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2551, 123)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebd6c093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyPresentWeatherType</th>\n",
       "      <th>HourlyPressureChange</th>\n",
       "      <th>...</th>\n",
       "      <th>BackupElevation</th>\n",
       "      <th>BackupEquipment</th>\n",
       "      <th>BackupLatitude</th>\n",
       "      <th>BackupLongitude</th>\n",
       "      <th>BackupName</th>\n",
       "      <th>WindEquipmentChangeDate</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>30.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006/9/18</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-02 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006/9/18</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-03 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>29.78</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006/9/18</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-01-04 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>30.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006/9/18</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-05 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>29.97</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006/9/18</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                DATE  LATITUDE  LONGITUDE HourlyAltimeterSetting  \\\n",
       "0      0 2009-01-01 00:51:00  40.77898  -73.96925                  30.01   \n",
       "1      1 2009-01-02 00:51:00  40.77898  -73.96925                   30.2   \n",
       "2      2 2009-01-03 00:51:00  40.77898  -73.96925                  29.78   \n",
       "3      3 2009-01-04 00:51:00  40.77898  -73.96925                  30.07   \n",
       "4      4 2009-01-05 00:51:00  40.77898  -73.96925                  29.97   \n",
       "\n",
       "  HourlyDewPointTemperature HourlyDryBulbTemperature HourlyPrecipitation  \\\n",
       "0                       3.0                     18.0                   0   \n",
       "1                       1.0                     25.0                   0   \n",
       "2                      21.0                     32.0                   0   \n",
       "3                       9.0                     28.0                   0   \n",
       "4                      14.0                     39.0                   0   \n",
       "\n",
       "  HourlyPresentWeatherType HourlyPressureChange  ...  BackupElevation  \\\n",
       "0                        0                -0.04  ...              0.0   \n",
       "1                        0                 0.06  ...              0.0   \n",
       "2                        0                -0.02  ...              0.0   \n",
       "3                        0                    0  ...              0.0   \n",
       "4                        0                 0.06  ...              0.0   \n",
       "\n",
       "   BackupEquipment BackupLatitude BackupLongitude        BackupName  \\\n",
       "0        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
       "1        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
       "2        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
       "3        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
       "4        SNOWBOARD            0.0             0.0  CENTRAL PARK ZOO   \n",
       "\n",
       "  WindEquipmentChangeDate  YEAR MONTH  DAY  WEEK  \n",
       "0               2006/9/18  2009     1    1     4  \n",
       "1               2006/9/18  2009     1    2     5  \n",
       "2               2006/9/18  2009     1    3     6  \n",
       "3               2006/9/18  2009     1    4     7  \n",
       "4               2006/9/18  2009     1    5     1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3efad785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      18.0\n",
       "1       3.0\n",
       "2       8.0\n",
       "3      10.0\n",
       "4       7.0\n",
       "       ... \n",
       "360     6.0\n",
       "361     8.0\n",
       "362    11.0\n",
       "363     0.0\n",
       "364     5.0\n",
       "Name: HourlyWindSpeed, Length: 2551, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data[\"HourlyWindSpeed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51d865",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "491f6344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>cal_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-29 18:59:06</td>\n",
       "      <td>2015-01-29 19:05:18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.957012</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1.017352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-08 22:59:42</td>\n",
       "      <td>2015-01-08 23:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.957418</td>\n",
       "      <td>40.718804</td>\n",
       "      <td>-73.959905</td>\n",
       "      <td>40.710880</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.906701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-06 08:41:30</td>\n",
       "      <td>2015-01-06 09:05:51</td>\n",
       "      <td>5</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>237</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-73.995135</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.501233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-22 14:44:21</td>\n",
       "      <td>2015-01-22 14:54:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.999917</td>\n",
       "      <td>40.748428</td>\n",
       "      <td>-73.985156</td>\n",
       "      <td>40.748575</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1.244959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-15 14:53:41</td>\n",
       "      <td>2015-01-15 15:02:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2.635661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0        0         1  2015-01-29 18:59:06   2015-01-29 19:05:18   \n",
       "1        1         2  2015-01-08 22:59:42   2015-01-08 23:04:00   \n",
       "2        2         2  2015-01-06 08:41:30   2015-01-06 09:05:51   \n",
       "3        3         1  2015-01-22 14:44:21   2015-01-22 14:54:12   \n",
       "4        4         1  2015-01-15 14:53:41   2015-01-15 15:02:40   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                1           0.90           1                  N   \n",
       "1                1           1.04           1                  N   \n",
       "2                5           1.41           1                  N   \n",
       "3                1           1.10           1                  N   \n",
       "4                1           1.60           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  ...  pickup_longitude  pickup_latitude  \\\n",
       "0           262           236  ...        -73.946510        40.775932   \n",
       "1           255           256  ...        -73.957418        40.718804   \n",
       "2           237            50  ...        -73.965635        40.768615   \n",
       "3            68           164  ...        -73.999917        40.748428   \n",
       "4           263           142  ...        -73.951010        40.778766   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  YEAR  MONTH  DAY  HOUR  WEEK  \\\n",
       "0         -73.957012         40.780436  2015      1   29    18     4   \n",
       "1         -73.959905         40.710880  2015      1    8    22     4   \n",
       "2         -73.995135         40.766238  2015      1    6     8     2   \n",
       "3         -73.985156         40.748575  2015      1   22    14     4   \n",
       "4         -73.981532         40.773633  2015      1   15    14     4   \n",
       "\n",
       "   cal_distance  \n",
       "0      1.017352  \n",
       "1      0.906701  \n",
       "2      2.501233  \n",
       "3      1.244959  \n",
       "4      2.635661  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data = taxi_data.drop([\"index\"], axis=1)\n",
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d5ad718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'YEAR', 'MONTH', 'DAY', 'HOUR',\n",
       "       'WEEK', 'cal_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "113269ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.95\n",
       "1       0.00\n",
       "2       1.00\n",
       "3       0.00\n",
       "4       0.00\n",
       "        ... \n",
       "2559    0.00\n",
       "2560    0.00\n",
       "2561    0.00\n",
       "2562    2.00\n",
       "2563    2.15\n",
       "Name: tip_amount, Length: 10256, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data[\"tip_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b566ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'DATE',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'HourlyAltimeterSetting',\n",
       " 'HourlyDewPointTemperature',\n",
       " 'HourlyDryBulbTemperature',\n",
       " 'HourlyPrecipitation',\n",
       " 'HourlyPresentWeatherType',\n",
       " 'HourlyPressureChange',\n",
       " 'HourlyPressureTendency',\n",
       " 'HourlyRelativeHumidity',\n",
       " 'HourlySkyConditions',\n",
       " 'HourlySeaLevelPressure',\n",
       " 'HourlyStationPressure',\n",
       " 'HourlyVisibility',\n",
       " 'HourlyWetBulbTemperature',\n",
       " 'HourlyWindDirection',\n",
       " 'HourlyWindGustSpeed',\n",
       " 'HourlyWindSpeed',\n",
       " 'Sunrise',\n",
       " 'Sunset',\n",
       " 'DailyAverageDewPointTemperature',\n",
       " 'DailyAverageDryBulbTemperature',\n",
       " 'DailyAverageRelativeHumidity',\n",
       " 'DailyAverageSeaLevelPressure',\n",
       " 'DailyAverageStationPressure',\n",
       " 'DailyAverageWetBulbTemperature',\n",
       " 'DailyAverageWindSpeed',\n",
       " 'DailyCoolingDegreeDays',\n",
       " 'DailyDepartureFromNormalAverageTemperature',\n",
       " 'DailyHeatingDegreeDays',\n",
       " 'DailyMaximumDryBulbTemperature',\n",
       " 'DailyMinimumDryBulbTemperature',\n",
       " 'DailyPeakWindDirection',\n",
       " 'DailyPeakWindSpeed',\n",
       " 'DailyPrecipitation',\n",
       " 'DailySnowDepth',\n",
       " 'DailySnowfall',\n",
       " 'DailySustainedWindDirection',\n",
       " 'DailySustainedWindSpeed',\n",
       " 'DailyWeather',\n",
       " 'MonthlyAverageRH',\n",
       " 'MonthlyDaysWithGT001Precip',\n",
       " 'MonthlyDaysWithGT010Precip',\n",
       " 'MonthlyDaysWithGT32Temp',\n",
       " 'MonthlyDaysWithGT90Temp',\n",
       " 'MonthlyDaysWithLT0Temp',\n",
       " 'MonthlyDaysWithLT32Temp',\n",
       " 'MonthlyDepartureFromNormalAverageTemperature',\n",
       " 'MonthlyDepartureFromNormalCoolingDegreeDays',\n",
       " 'MonthlyDepartureFromNormalHeatingDegreeDays',\n",
       " 'MonthlyDepartureFromNormalMaximumTemperature',\n",
       " 'MonthlyDepartureFromNormalMinimumTemperature',\n",
       " 'MonthlyDepartureFromNormalPrecipitation',\n",
       " 'MonthlyDewpointTemperature',\n",
       " 'MonthlyGreatestPrecip',\n",
       " 'MonthlyGreatestPrecipDate',\n",
       " 'MonthlyGreatestSnowDepth',\n",
       " 'MonthlyGreatestSnowDepthDate',\n",
       " 'MonthlyGreatestSnowfall',\n",
       " 'MonthlyGreatestSnowfallDate',\n",
       " 'MonthlyMaxSeaLevelPressureValue',\n",
       " 'MonthlyMaxSeaLevelPressureValueDate',\n",
       " 'MonthlyMaxSeaLevelPressureValueTime',\n",
       " 'MonthlyMaximumTemperature',\n",
       " 'MonthlyMeanTemperature',\n",
       " 'MonthlyMinSeaLevelPressureValue',\n",
       " 'MonthlyMinSeaLevelPressureValueDate',\n",
       " 'MonthlyMinSeaLevelPressureValueTime',\n",
       " 'MonthlyMinimumTemperature',\n",
       " 'MonthlySeaLevelPressure',\n",
       " 'MonthlyStationPressure',\n",
       " 'MonthlyTotalLiquidPrecipitation',\n",
       " 'MonthlyTotalSnowfall',\n",
       " 'MonthlyWetBulb',\n",
       " 'AWND',\n",
       " 'CDSD',\n",
       " 'CLDD',\n",
       " 'DSNW',\n",
       " 'HDSD',\n",
       " 'HTDD',\n",
       " 'NormalsCoolingDegreeDay',\n",
       " 'NormalsHeatingDegreeDay',\n",
       " 'ShortDurationEndDate005',\n",
       " 'ShortDurationEndDate010',\n",
       " 'ShortDurationEndDate015',\n",
       " 'ShortDurationEndDate020',\n",
       " 'ShortDurationEndDate030',\n",
       " 'ShortDurationEndDate045',\n",
       " 'ShortDurationEndDate060',\n",
       " 'ShortDurationEndDate080',\n",
       " 'ShortDurationEndDate100',\n",
       " 'ShortDurationEndDate120',\n",
       " 'ShortDurationEndDate150',\n",
       " 'ShortDurationEndDate180',\n",
       " 'ShortDurationPrecipitationValue005',\n",
       " 'ShortDurationPrecipitationValue010',\n",
       " 'ShortDurationPrecipitationValue015',\n",
       " 'ShortDurationPrecipitationValue020',\n",
       " 'ShortDurationPrecipitationValue030',\n",
       " 'ShortDurationPrecipitationValue045',\n",
       " 'ShortDurationPrecipitationValue060',\n",
       " 'ShortDurationPrecipitationValue080',\n",
       " 'ShortDurationPrecipitationValue100',\n",
       " 'ShortDurationPrecipitationValue120',\n",
       " 'ShortDurationPrecipitationValue150',\n",
       " 'ShortDurationPrecipitationValue180',\n",
       " 'REM',\n",
       " 'BackupDirection',\n",
       " 'BackupDistance',\n",
       " 'BackupDistanceUnit',\n",
       " 'BackupElements',\n",
       " 'BackupElevation',\n",
       " 'BackupEquipment',\n",
       " 'BackupLatitude',\n",
       " 'BackupLongitude',\n",
       " 'BackupName',\n",
       " 'WindEquipmentChangeDate',\n",
       " 'YEAR',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'HOUR',\n",
       " 'WEEK']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hourly_weather_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "- 1. Create a database\n",
    "- 2. Write schema sql of taxi data, uber data, hourly weather data and daily weather data\n",
    "- 3. Create and populate four tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE TIMESTAMP,\n",
    "    tpep_pickup_datetime TIMESTAMP,\n",
    "    tpep_dropoff_datetime TIMESTAMP,\n",
    "    trip_distance FLOAT,\n",
    "    total_amount FLOAT,\n",
    "    tip_amount FLOAT,\n",
    "    passenger_count INTEGER,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    cal_distance FLOAT,\n",
    "    YEAR INTEGER, \n",
    "    MONTH INTEGER, \n",
    "    DAY INTEGER, \n",
    "    HOUR INTEGER,\n",
    "    WEEK INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime TIMESTAMP,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude  FLOAT,\n",
    "    dropoff_longitude FLOAT, \n",
    "    dropoff_latitude FLOAT,\n",
    "    passenger_count INTEGER,\n",
    "    YEAR  INTEGER,\n",
    "    MONTH  INTEGER, \n",
    "    DAY  INTEGER,\n",
    "    HOUR  INTEGER,\n",
    "    WEEK  INTEGER,\n",
    "    cal_distance FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE TIMESTAMP,\n",
    "    LATITUDE FLOAT,\n",
    "    LONGITUDE FLOAT,\n",
    "     YEAR INTEGER,\n",
    "     MONTH INTEGER,\n",
    "     DAY INTEGER,\n",
    "     WEEK INTEGER,\n",
    "     HOUR INTEGER,\n",
    "     HourlyPrecipitation FLOAT,\n",
    "     HourlyWindSpeed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE TIMESTAMP,\n",
    "    LATITUDE FLOAT,\n",
    "    LONGITUDE FLOAT,\n",
    "    DailyAverageWindSpeed FLOAT, \n",
    "    DailyPrecipitation FLOAT,    \n",
    "     YEAR INTEGER,\n",
    "     MONTH INTEGER,\n",
    "     DAY INTEGER,\n",
    "     WEEK INTEGER  \n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "#     pass\n",
    "    connection.execute(TAXI_TRIPS_SCHEMA)\n",
    "with engine.connect() as connection:\n",
    "#     pass\n",
    "    connection.execute(UBER_TRIPS_SCHEMA)  \n",
    "with engine.connect() as connection:\n",
    "#     pass\n",
    "    connection.execute(HOURLY_WEATHER_SCHEMA)\n",
    "with engine.connect() as connection:\n",
    "#     pass\n",
    "    connection.execute(DAILY_WEATHER_SCHEMA)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "- 1. Write dataframe data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for table_name in table_to_df_dict:\n",
    "        table_to_df_dict[ table_name ].to_sql(table_name, engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaab54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc43d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
